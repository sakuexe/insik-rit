{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada6a850",
   "metadata": {},
   "source": [
    "\n",
    "# Exercise 4 : Diffusion Models\n",
    "\n",
    "In this lab, we will gain hands-on experience using pre-trained Diffusion Models to generate images based on textual prompts.\n",
    "\n",
    "## Objectives:\n",
    "- Set up the environment to run Diffusion Models.\n",
    "- Load and use a pre-trained diffusion model.\n",
    "- Generate images from textual prompts using the model.\n",
    "- Experiment with parameters like guidance scale and inference steps to observe their effects.\n",
    "\n",
    "\n",
    "\n",
    "## Environment Setup\n",
    "We will first install the necessary libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca4c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install necessary libraries\n",
    "!pip install diffusers transformers torch numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f8b5e",
   "metadata": {},
   "source": [
    "\n",
    "## Verifying Installation\n",
    "\n",
    "We will now verify the installation of the required libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecafac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import diffusers\n",
    "import transformers\n",
    "import torch\n",
    "import numpy\n",
    "\n",
    "print(\"Libraries installed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48813a2",
   "metadata": {},
   "source": [
    "\n",
    "## Loading the Stable Diffusion Pipeline\n",
    "\n",
    "Now we will load the pre-trained Stable Diffusion model pipeline. Make sure to use GPU if available for faster performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650eb872",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id, revision=\"fp16\", torch_dtype=torch.float16\n",
    ")\n",
    "pipe = pipe.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccd4e7e",
   "metadata": {},
   "source": [
    "\n",
    "## Generating Your First Image\n",
    "\n",
    "Now we will define a textual prompt and generate an image based on the prompt using the Stable Diffusion pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6820aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"A futuristic cityscape at sunset\"\n",
    "image = pipe(prompt).images[0]\n",
    "\n",
    "# Save the generated image\n",
    "image.save(\"cityscape.png\")\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff00712",
   "metadata": {},
   "source": [
    "\n",
    "## Experimenting with Parameters\n",
    "\n",
    "We will now experiment with adjusting the **guidance scale** and **number of inference steps** to see how they affect the generated images.\n",
    "\n",
    "- **Guidance Scale**: Controls how closely the image adheres to the prompt.\n",
    "- **Number of Inference Steps**: Affects the quality and generation time of the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e50d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = pipe(prompt, guidance_scale=5.0).images[0]\n",
    "image.save(\"cityscape_guidance5.png\")\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce51a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = pipe(prompt, num_inference_steps=100).images[0]\n",
    "image.save(\"cityscape_steps100.png\")\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0562e8",
   "metadata": {},
   "source": [
    "\n",
    "## Batch Generation\n",
    "\n",
    "We will now generate multiple images at once by providing a list of prompts to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f66f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompts = [\"A serene forest landscape\", \"An astronaut riding a horse\"]\n",
    "images = pipe(prompts).images\n",
    "\n",
    "for idx, img in enumerate(images):\n",
    "    img.save(f\"image_{idx}.png\")\n",
    "    img.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
