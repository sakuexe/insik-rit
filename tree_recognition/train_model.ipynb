{"nbformat":4,"nbformat_minor":5,"metadata":{"language_info":{"nbconvert_exporter":"python","file_extension":".py","mimetype":"text\/x-python","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.11.10","pygments_lexer":"ipython3"},"kernelspec":{"name":"python3","display_name":"devAI","language":"python"}},"cells":[{"source":["# Rock-Paper-Scissors Image Classification with PyTorch\n","\n","In this notebook, we will build a Convolutional Neural Network (CNN) using PyTorch to classify images of rock, paper, and scissors. We will train the model on a dataset of images and evaluate its performance on a validation set.\n"],"id":"860abdb1","cell_type":"markdown","metadata":{"collapsed":false}},{"metadata":{"collapsed":false},"id":"12e98aea","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import ImageFolder\n","from torchvision.transforms import Compose, Resize, ToTensor\n","from torch.utils.tensorboard import SummaryWriter\n"],"cell_type":"code","outputs":[],"execution_count":3},{"metadata":{"collapsed":false},"id":"fc30cbca","source":["# Check for GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'Using device: {device}')\n"],"cell_type":"code","outputs":[],"execution_count":4},{"metadata":{"collapsed":false},"id":"cefb6416","source":["# TensorBoard writer\n","writer = SummaryWriter('runs\/rock_paper_scissors_experiment')\n"],"cell_type":"code","outputs":[],"execution_count":5},{"source":["## Load and Preprocess the Dataset\n","\n","We will use `ImageFolder` to load our dataset, which expects images to be organized in subdirectories based on their class labels. We will apply transformations to resize the images and convert them to tensors.\n"],"id":"fac60aa5","cell_type":"markdown","metadata":{"collapsed":false}},{"metadata":{"collapsed":false},"id":"57e6621a","source":["# Transformations\n","transform = Compose([Resize((28, 28)), ToTensor()])\n","\n","# Load the dataset\n","train_data = ImageFolder(root='rps', transform=transform)\n","val_data = ImageFolder(root='rps-test-set', transform=transform)\n","\n","# Print class names\n","print('Classes:', train_data.classes)\n"],"cell_type":"code","outputs":[],"execution_count":6},{"metadata":{"collapsed":false},"id":"0def71a7","source":["# Create data loaders\n","train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n","val_loader = DataLoader(val_data, batch_size=16, shuffle=False)\n"],"cell_type":"code","outputs":[],"execution_count":7},{"source":["#### Display some samples from the dataset\n"],"id":"500e7b3b","cell_type":"markdown","metadata":{"collapsed":false}},{"metadata":{"collapsed":false},"id":"1d0e4dd5","source":["from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","# Paths to the images\n","image_paths = [\n","    \"rps\/paper\/paper02-089.png\",\n","    \"rps\/rock\/rock06ck02-100.png\",\n","    \"rps\/scissors\/testscissors02-006.png\"\n","]\n","\n","# Load the images\n","images = [Image.open(image_path) for image_path in image_paths]\n","titles = ['Paper', 'Rock', 'Scissors']\n","\n","# Display the images\n","fig, axs = plt.subplots(1, 3, figsize=(12, 5))\n","for ax, image, title in zip(axs, images, titles):\n","    ax.imshow(image)\n","    ax.axis('off')  # Hide axis ticks\n","    ax.set_title(title)\n","\n","plt.tight_layout()\n","plt.show()\n"],"cell_type":"code","outputs":[],"execution_count":8},{"source":["## Define a Simple CNN Model\n","\n","We will define a simple Convolutional Neural Network (CNN) with two convolutional layers followed by two fully connected layers.\n"],"id":"526ba57f","cell_type":"markdown","metadata":{"collapsed":false}},{"metadata":{"collapsed":false},"id":"74bb6877","source":["# Define the CNN model\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n","        self.fc2 = nn.Linear(128, len(train_data.classes))  # Number of classes\n","\n","    def forward(self, x):\n","        x = self.pool(torch.relu(self.conv1(x)))\n","        x = self.pool(torch.relu(self.conv2(x)))\n","        x = x.view(-1, 32 * 7 * 7)  # Flattening the tensor for the fully connected layers\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n"],"cell_type":"code","outputs":[],"execution_count":9},{"source":["## Initialize the Model, Loss Function, and Optimizer\n","\n","We will create an instance of the CNN model, define the loss function as Cross Entropy Loss, and use SGD optimizer.\n"],"id":"f6a0dbdc","cell_type":"markdown","metadata":{"collapsed":false}},{"metadata":{"collapsed":false},"id":"42181f85","source":["# Initialize the model\n","model = SimpleCNN().to(device)  # Move the model to the appropriate device\n","\n","# Loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n"],"cell_type":"code","outputs":[],"execution_count":10},{"source":["## Train the Model\n","\n","We will define a function to train the model and monitor its performance on the validation set after each epoch. The best model weights will be saved based on validation loss.\n"],"id":"0879f14b","cell_type":"markdown","metadata":{"collapsed":false}},{"metadata":{"collapsed":false},"id":"71164087","source":["# Training function\n","def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n","    best_val_loss = float('inf')\n","\n","    for epoch in range(num_epochs):\n","        running_train_loss = 0.0\n","        model.train()\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_train_loss += loss.item()\n","\n","        train_loss = running_train_loss \/ len(train_loader)\n","\n","        # Validation\n","        running_val_loss = 0.0\n","        correct = 0\n","        total = 0\n","        model.eval()\n","        with torch.no_grad():\n","            for inputs, labels in val_loader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","                running_val_loss += loss.item()\n","\n","                # Calculate validation accuracy\n","                _, predicted = torch.max(outputs, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        val_loss = running_val_loss \/ len(val_loader)\n","        val_accuracy = 100 * correct \/ total\n","\n","        print(f'Epoch [{epoch+1}\/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n","\n","        # Log losses and accuracy to TensorBoard\n","        writer.add_scalar('Loss\/train', train_loss, epoch)\n","        writer.add_scalar('Loss\/validation', val_loss, epoch)\n","        writer.add_scalar('Accuracy\/validation', val_accuracy, epoch)\n","\n","        # Save the best model\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            torch.save(model.state_dict(), 'best_model_weights.pth')\n","            print(f\"Model saved at epoch {epoch+1}\")\n","\n","    writer.close()\n"],"cell_type":"code","outputs":[],"execution_count":11},{"metadata":{"collapsed":false},"id":"50864f94","source":["# Train the model\n","train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n"],"cell_type":"code","outputs":[],"execution_count":12},{"source":["## Load the Best Model for Inference\n","\n","After training, we will load the best model weights saved during training for inference.\n"],"id":"0a201f5f","cell_type":"markdown","metadata":{"collapsed":false}},{"metadata":{"collapsed":false},"id":"354192d1","source":["# Load the best model for inference\n","model.load_state_dict(torch.load('best_model_weights.pth'))\n","model.eval()\n"],"cell_type":"code","outputs":[],"execution_count":13},{"source":["## Perform Inference on a Single Image\n","\n","We will define a function to perform inference on a single image and predict its class label.\n"],"id":"ec813de3","cell_type":"markdown","metadata":{"collapsed":false}},{"metadata":{"collapsed":false},"id":"cff214f7","source":["# Function to perform inference on a single image\n","from PIL import Image\n","\n","def infer_single_image(model, image_path, transform, classes):\n","    # Load and preprocess the image\n","    image = Image.open(image_path).convert('RGB')\n","    image = transform(image)\n","    image = image.unsqueeze(0)  # Add batch dimension\n","\n","    # Move to device\n","    image = image.to(device)\n","\n","    # Forward pass\n","    with torch.no_grad():\n","        output = model(image)\n","        _, predicted = torch.max(output, 1)\n","        predicted_class = classes[predicted.item()]\n","    return predicted_class\n"],"cell_type":"code","outputs":[],"execution_count":15},{"source":["## Just to Make It More Interactive, I Added Gradio Flavor!\n","\n","*Warning:* This notebook now contains traces of Gradio. Side effects may include uncontrollable excitement and a sudden urge to classify everything you see!\n","\n"],"id":"ca42b897","cell_type":"markdown","metadata":{"collapsed":false}},{"metadata":{"collapsed":false},"id":"87a81407","source":["# Install Gradio if not already installed\n","!pip install gradio\n","\n","# Import Gradio\n","import gradio as gr\n","\n","# Ensure the model is in evaluation mode\n","model.eval()\n","\n","# Define the prediction function\n","def predict(image):\n","    # Apply the same transformations as during training\n","    image = transform(image).unsqueeze(0).to(device)\n","    with torch.no_grad():\n","        output = model(image)\n","        _, predicted = torch.max(output, 1)\n","        predicted_class = train_data.classes[predicted.item()]\n","    return predicted_class\n","\n","# Create the Gradio interface\n","iface = gr.Interface(\n","    fn=predict,\n","    inputs=gr.Image(type=\"pil\"),\n","    outputs=\"text\",\n","    title=\"Rock-Paper-Scissors Classifier\",\n","    description=\"Upload an image of rock, paper, or scissors, and the model will predict its class.\"\n",")\n","\n","# Launch the Gradio app\n","iface.launch(share=True)\n"],"cell_type":"code","outputs":[],"execution_count":16}]}